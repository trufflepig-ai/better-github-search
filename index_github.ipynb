{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKN05p8-ubMP"
      },
      "source": [
        "# Index GitHub repos using Trufflepig\n",
        "\n",
        "In order to standardize the input data for each repository, we will be generating descriptions using Claude-3 Haiku and providing it with the description of the repo and a README if available.\n",
        "\n",
        "## 1. Import trufflepig and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2jmHlzVuReP"
      },
      "outputs": [],
      "source": [
        "!pip install trufflepig-py\n",
        "!pip install anthropic\n",
        "!pip install tiktoken\n",
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx06xiHXvNbp"
      },
      "outputs": [],
      "source": [
        "from trufflepig import Trufflepig\n",
        "import requests\n",
        "import base64\n",
        "import time\n",
        "import anthropic\n",
        "from langdetect import detect\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcdh6DhpvQJp"
      },
      "source": [
        "## 2. Get API Keys for the necessary services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt-JMJqjvOF1"
      },
      "outputs": [],
      "source": [
        "TRUFFLEPIG_API_KEY = 'your-api-key'\n",
        "GITHUB_TOKEN = 'your-api-key'\n",
        "ANTHROPIC_KEY = 'your-api-key'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "418RrfDQ53VI"
      },
      "source": [
        "## 3. Generate better descriptions for each repo\n",
        "We're also using Haiku to filter out certain repositories that are just collections of links or deprecated projects that may cause worse search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09hymClCwLCF"
      },
      "outputs": [],
      "source": [
        "def fetch_readme(repo, headers):\n",
        "    readme_files = [\"README.md\", \"readme.md\", \"README\", \"readme\", \"README.rst\", \"readme.rst\", \"README_en.md\", \"readme_en.md\", \"README_EN.md\"]\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    for readme_file in readme_files:\n",
        "        readme_url = repo['contents_url'].replace('{+path}', readme_file)\n",
        "        readme_response = requests.get(readme_url, headers=headers)\n",
        "        if readme_response.status_code == 200:\n",
        "            response_json = readme_response.json()\n",
        "            if isinstance(response_json, dict) and 'content' in response_json:\n",
        "                readme_data = response_json['content']\n",
        "                if readme_data:\n",
        "                    readme_text = base64.b64decode(readme_data).decode('utf-8')\n",
        "                    try:\n",
        "                        # Check if the README is in English or is explicitly an English README file\n",
        "                        if detect(readme_text) == 'en' or 'en' in readme_file:\n",
        "                            readme_tokens = encoding.encode(readme_text, disallowed_special=())\n",
        "                            truncated_readme = encoding.decode(readme_tokens[:750])\n",
        "                            return truncated_readme\n",
        "                    except tiktoken.DisallowedSpecialTokenError as e:\n",
        "                        print(f\"Encoding error for {readme_file} in repository {repo['name']}: {str(e)}\")\n",
        "            else:\n",
        "                print(f\"Unexpected response format for {readme_file} in repository {repo['name']}: {response_json}\")\n",
        "    return \"\"\n",
        "\n",
        "def generate_description(repo, readme_text, client):\n",
        "    prompt = f'''\n",
        "    Using the provided context, provide a concise description (no more than 3 sentences) of the repository. If the repository primarily consists of a collection of external resources and links or lacks a clear and original purpose, return \"Not Substantial\".\n",
        "\n",
        "    Here are two examples:\n",
        "\n",
        "    Example for a substantial repository:\n",
        "\n",
        "    <example_input>\n",
        "    Repository Name: DeepLearningModels\n",
        "    Repository Description: A comprehensive collection of pre-trained models designed for natural language processing and computer vision.\n",
        "    Readme: Includes installation instructions, usage examples, and links to research papers.\n",
        "    </example_input>\n",
        "\n",
        "    <example_output>\n",
        "    The 'DeepLearningModels' repository contains wide array of advanced, ready-to-use AI models. It supports multiple languages and frameworks, and provides thorough documentation, making it accessible for both beginners and experts.\n",
        "    </example_output>\n",
        "\n",
        "    Example for a non-substantial repository:\n",
        "\n",
        "    <example_input>\n",
        "    Repository Name: UsefulLinks\n",
        "    Repository Description: A curated list of links to tutorials, datasets, and tools for machine learning.\n",
        "    Readme: Mainly contains hyperlinks to external websites.\n",
        "    </example_input>\n",
        "\n",
        "    <example_output>\n",
        "    Not Substantial\n",
        "    </example_output>\n",
        "\n",
        "    <repository_name>{repo['name']}</repository_name>\n",
        "    <repository_description>{repo['description']}</repository_description>\n",
        "    <readme>{readme_text}</readme>\n",
        "    '''\n",
        "\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=1024,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    print(response.content[0].text)\n",
        "    return response.content[0].text\n",
        "\n",
        "def fetch_repositories(min_stars, client, page):\n",
        "    url = 'https://api.github.com/search/repositories'\n",
        "    headers = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "    params = {\n",
        "        'q': f'stars:>{min_stars}',\n",
        "        'sort': 'stars',\n",
        "        'order': 'asc',\n",
        "        'per_page': 100,\n",
        "        'page': page\n",
        "    }\n",
        "    results = []\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        response.raise_for_status()\n",
        "        repositories = response.json()['items']\n",
        "        for repo in repositories:\n",
        "            readme_text = fetch_readme(repo, headers)\n",
        "            if readme_text and len(readme_text) > 0:\n",
        "                description = generate_description(repo, readme_text, client)\n",
        "                if \"Not Substantial\" not in description:  # Skip adding if marked not substantial\n",
        "                    results.append((repo['html_url'], description, repo['stargazers_count'], repo['language'], repo['description']))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "        return []\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EqitxH06-fV"
      },
      "source": [
        "Each query to Github's search API only provided 10 pages of results so we had to do this next step a few times. We generated descriptions for over 8000 repositories with a minimum of 1000 stars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSaBtBFi66et"
      },
      "outputs": [],
      "source": [
        "anthropic_client = anthropic.Anthropic(\n",
        "    api_key=ANTHROPIC_KEY,\n",
        ")\n",
        "results = []\n",
        "for i in range (1, 11):\n",
        "  temp_results = fetch_repositories(4000, anthropic_client, i)\n",
        "  results.extend(temp_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfFGXp9t7iH_"
      },
      "source": [
        "## 4. Index repo descriptions as documents in Trufflepig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JXKUHP17ho2"
      },
      "outputs": [],
      "source": [
        "client = Trufflepig(api_key=TRUFFLEPIG_API_KEY)\n",
        "\n",
        "index = client.get_index('github-search-engine')\n",
        "if not index:\n",
        "  index = client.create_index('github-search-engine')\n",
        "for idx in range(0, len(results), 10):\n",
        "  uploads = [{'document_key': repo[0], 'document': repo[1], 'metadata': {'stars': repo[2], 'language': repo[3], 'description': repo[4] }} for repo in results[idx:idx + 10]]\n",
        "  tracking_ids = index.upload(uploads)\n",
        "  upload_status = index.get_upload_status(tracking_ids)\n",
        "\n",
        "  while any(status.job_status == 'IN_PROGRESS' for status in upload_status):\n",
        "    status_strings = [f'{status.document_key}: {status.job_status}' for status in upload_status]\n",
        "    print(status_strings)\n",
        "    time.sleep(5)\n",
        "    upload_status = index.get_upload_status(tracking_ids)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
